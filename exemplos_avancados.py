"""
Exemplos Avan√ßados - Chat OpenAI com Mem√≥ria

Demonstra casos de uso mais complexos e t√©cnicas avan√ßadas.

IMPORTANTE: Todas as configura√ß√µes s√£o carregadas do arquivo .env
O sistema falhar√° se qualquer vari√°vel obrigat√≥ria estiver faltando.
"""

from chat_openai_memoria import ChatComMemoria
import time


def exemplo_multiplas_personalidades():
    """Demonstra como usar diferentes personalidades em chats separados"""
    
    print("\n" + "="*60)
    print("EXEMPLO: M√öLTIPLAS PERSONALIDADES")
    print("="*60 + "\n")
    
    # Chat 1: Professor de Python
    professor = ChatComMemoria()
    professor.definir_personalidade(
        "Voc√™ √© um professor de Python experiente. "
        "Responda de forma did√°tica e use exemplos pr√°ticos."
    )
    
    # Chat 2: Code Reviewer
    reviewer = ChatComMemoria()
    reviewer.definir_personalidade(
        "Voc√™ √© um code reviewer experiente. "
        "Analise c√≥digo criticamente e sugira melhorias."
    )
    
    # Pergunta ao professor
    print("PERGUNTANDO AO PROFESSOR:")
    codigo_exemplo = """
def calcular(a, b):
    return a + b
"""
    pergunta = f"Como posso melhorar esta fun√ß√£o?\n{codigo_exemplo}"
    resposta_prof = professor.enviar_mensagem(pergunta)
    print(f"Professor: {resposta_prof}\n")
    
    # Mesma pergunta ao reviewer
    print("-"*60)
    print("\nPERGUNTANDO AO REVIEWER:")
    resposta_review = reviewer.enviar_mensagem(pergunta)
    print(f"Reviewer: {resposta_review}\n")
    
    print("="*60)
    print("Nota: Respostas diferentes devido a personalidades distintas")
    print("="*60 + "\n")


def exemplo_controle_contexto():
    """Demonstra controle de contexto e limpeza estrat√©gica de mem√≥ria"""
    
    print("\n" + "="*60)
    print("EXEMPLO: CONTROLE DE CONTEXTO")
    print("="*60 + "\n")
    
    chat = ChatComMemoria()
    
    # Primeira conversa sobre Python
    print("T√ìPICO 1: Python")
    chat.enviar_mensagem("Vamos falar sobre Python. O que s√£o decorators?")
    chat.enviar_mensagem("Pode dar um exemplo de decorator?")
    
    print(f"Mensagens no hist√≥rico: {len(chat.historico)}")
    print(f"Tokens aproximados: {chat.contar_tokens_aproximado()}\n")
    
    # Muda de t√≥pico - limpa contexto
    print("-"*60)
    print("\nMudando de t√≥pico - limpando contexto anterior\n")
    chat.limpar_historico()
    
    # Segunda conversa sobre JavaScript
    print("T√ìPICO 2: JavaScript")
    resposta = chat.enviar_mensagem("Vamos falar sobre JavaScript. O que s√£o Promises?")
    print(f"Resposta: {resposta[:100]}...\n")
    
    print(f"Mensagens no hist√≥rico: {len(chat.historico)}")
    print(f"Tokens aproximados: {chat.contar_tokens_aproximado()}\n")
    
    print("="*60)
    print("Nota: Limpar mem√≥ria ajuda a reduzir custos e manter foco")
    print("="*60 + "\n")


def exemplo_conversa_longa():
    """Demonstra como gerenciar conversas longas com controle de tokens"""
    
    print("\n" + "="*60)
    print("EXEMPLO: GERENCIAMENTO DE CONVERSA LONGA")
    print("="*60 + "\n")
    
    chat = ChatComMemoria()
    
    # Simula v√°rias perguntas
    perguntas = [
        "O que √© Python?",
        "Quais s√£o os tipos de dados b√°sicos?",
        "Como funcionam as listas?",
        "E os dicion√°rios?",
        "O que s√£o fun√ß√µes?",
        "Como usar classes?",
        "O que s√£o m√≥dulos?",
        "Como fazer tratamento de erros?"
    ]
    
    MAX_TOKENS = 500  # Limite arbitr√°rio para exemplo
    
    for i, pergunta in enumerate(perguntas, 1):
        print(f"\n[{i}] Voc√™: {pergunta}")
        
        # Verifica tokens antes de enviar
        tokens_atuais = chat.contar_tokens_aproximado()
        print(f"Tokens no hist√≥rico: {tokens_atuais}")
        
        if tokens_atuais > MAX_TOKENS:
            print("ATEN√á√ÉO: Limite de tokens atingido - limpando hist√≥rico antigo")
            
            # Estrat√©gia: mant√©m apenas as √∫ltimas 2 mensagens
            if len(chat.historico) > 4:
                historico_recente = chat.historico[-4:]
                chat.historico = historico_recente
                print(f"Hist√≥rico reduzido para {len(chat.historico)} mensagens")
        
        resposta = chat.enviar_mensagem(pergunta)
        print(f"Assistente: {resposta[:100]}...")
    
    print("\n" + "="*60)
    print(f"Total de mensagens processadas: {i}")
    print(f"Mensagens mantidas em mem√≥ria: {len(chat.historico)}")
    print("="*60 + "\n")


def exemplo_tratamento_erros():
    """Demonstra tratamento de erros comuns"""
    
    print("\n" + "="*60)
    print("EXEMPLO: TRATAMENTO DE ERROS")
    print("="*60 + "\n")
    
    # Erro 1: API Key inv√°lida
    print("1. Testando com API Key inv√°lida:")
    print("Nota: Agora todas as configura√ß√µes v√™m do .env")
    print("Para testar erro de API Key, modifique OPENAI_API_KEY no .env\n")
    
    # Erro 2: API Key n√£o configurada
    print("2. Testando sem API Key:")
    print("Nota: Agora o sistema falha imediatamente se OPENAI_API_KEY n√£o estiver no .env")
    print("Para testar, remova ou comente OPENAI_API_KEY no .env\n")
    
    # Erro 3: Modelo inv√°lido
    print("3. Testando com modelo inv√°lido:")
    print("Nota: Agora o modelo vem do .env (OPENAI_MODEL)")
    print("Para testar erro de modelo, configure um modelo inv√°lido no .env\n")
    
    print("="*60)
    print("Nota: Sempre implemente try/except ao trabalhar com APIs")
    print("="*60 + "\n")


def exemplo_analise_codigo():
    """Exemplo pr√°tico: an√°lise de c√≥digo com contexto"""
    
    print("\n" + "="*60)
    print("EXEMPLO PR√ÅTICO: AN√ÅLISE DE C√ìDIGO")
    print("="*60 + "\n")
    
    chat = ChatComMemoria()
    chat.definir_personalidade(
        "Voc√™ √© um especialista em Python. "
        "Analise c√≥digo e sugira melhorias de forma objetiva."
    )
    
    # Envia c√≥digo para an√°lise
    codigo = """
def processar_dados(dados):
    resultado = []
    for i in range(len(dados)):
        if dados[i] > 0:
            resultado.append(dados[i] * 2)
    return resultado

numeros = [1, -2, 3, -4, 5]
print(processar_dados(numeros))
"""
    
    print("C√ìDIGO ORIGINAL:")
    print(codigo)
    print("-"*60)
    
    # Pergunta 1: An√°lise geral
    print("\n1. An√°lise geral:")
    resposta1 = chat.enviar_mensagem(f"Analise este c√≥digo:\n{codigo}")
    print(resposta1[:200] + "...\n")
    
    # Pergunta 2: Aproveita contexto
    print("-"*60)
    print("\n2. Pergunta de acompanhamento (usa contexto):")
    resposta2 = chat.enviar_mensagem("Como posso torn√°-lo mais pythonico?")
    print(resposta2[:200] + "...\n")
    
    # Pergunta 3: Continua no mesmo contexto
    print("-"*60)
    print("\n3. Outra pergunta de acompanhamento:")
    resposta3 = chat.enviar_mensagem("E quanto a performance?")
    print(resposta3[:200] + "...\n")
    
    print("="*60)
    print("Nota: Cada pergunta mant√©m o contexto das anteriores")
    print("="*60 + "\n")


def exemplo_janela_deslizante():
    """Demonstra o funcionamento do sliding window autom√°tico"""
    
    print("\n" + "="*60)
    print("EXEMPLO: SLIDING WINDOW (JANELA DESLIZANTE)")
    print("="*60 + "\n")
    
    # Cria chat com janela pequena para demonstra√ß√£o
    chat = ChatComMemoria(tamanho_janela=3)  # Mant√©m apenas 3 pares (6 mensagens)
    
    print("Configura√ß√£o: Janela de 3 pares (m√°ximo 6 mensagens)\n")
    print("-"*60 + "\n")
    
    # Envia v√°rias mensagens para demonstrar a janela
    perguntas = [
        "Qual √© a capital da Fran√ßa?",
        "E da Alemanha?",
        "E da It√°lia?",
        "E da Espanha?",
        "E de Portugal?",
    ]
    
    for i, pergunta in enumerate(perguntas, 1):
        print(f"[Mensagem {i}] {pergunta}")
        resposta = chat.enviar_mensagem(pergunta)
        print(f"Resposta: {resposta[:80]}...")
        print(f"Total no hist√≥rico: {len(chat.historico)} mensagens\n")
    
    print("-"*60)
    print("\nOBSERVA√á√ïES:")
    print("‚Ä¢ Ap√≥s a 4¬™ pergunta, o hist√≥rico para de crescer")
    print("‚Ä¢ As mensagens mais antigas s√£o automaticamente removidas")
    print("‚Ä¢ Apenas as √∫ltimas 3 pares (6 mensagens) s√£o mantidas")
    print("‚Ä¢ Isso reduz custos e mant√©m o contexto recente\n")
    
    chat.debug_memoria()


def exemplo_monitoramento_automatico():
    """Demonstra o sistema de monitoramento de tokens"""
    
    print("\n" + "="*60)
    print("EXEMPLO: MONITORAMENTO AUTOM√ÅTICO DE TOKENS")
    print("="*60 + "\n")
    
    # Cria chat com limite baixo para demonstra√ß√£o
    chat = ChatComMemoria(limite_maximo=300)
    
    print("Configura√ß√£o: Limite de 300 tokens\n")
    print("N√≠veis de alerta:")
    print("  üü¢ Verde: 0-100 tokens (0-33%)")
    print("  üü° Amarelo: 100-200 tokens (33-66%)")
    print("  üü† Laranja: 200-300 tokens (66-99%)")
    print("  üî¥ Vermelho: ‚â•300 tokens (‚â•100% - CR√çTICO)\n")
    print("-"*60 + "\n")
    
    # Envia mensagens gradualmente
    perguntas = [
        "Me explique o que √© Python em poucas palavras.",
        "Quais s√£o os principais tipos de dados em Python?",
        "Como funcionam as listas em Python?",
        "Explique o conceito de dicion√°rios em Python.",
        "O que s√£o fun√ß√µes em Python e como cri√°-las?",
    ]
    
    for i, pergunta in enumerate(perguntas, 1):
        print(f"\n[Pergunta {i}] {pergunta}")
        resposta = chat.enviar_mensagem(pergunta)
        print(f"Resposta recebida: {len(resposta)} caracteres")
        
        # O alerta ser√° exibido automaticamente por enviar_mensagem()
    
    print("\n" + "-"*60)
    print("\nStatus final:")
    chat.debug_memoria()
    
    print("OBSERVA√á√ïES:")
    print("‚Ä¢ Os alertas aparecem automaticamente conforme tokens aumentam")
    print("‚Ä¢ No n√≠vel vermelho, o sistema recomenda a√ß√£o (limpar ou ajustar janela)")
    print("‚Ä¢ Combine com sliding window para gerenciamento autom√°tico\n")


def exemplo_sistema_completo():
    """Demonstra uso de sliding window + monitoramento juntos"""
    
    print("\n" + "="*60)
    print("EXEMPLO: SISTEMA COMPLETO (SLIDING WINDOW + MONITORAMENTO)")
    print("="*60 + "\n")
    
    # Cria chat com ambas funcionalidades
    chat = ChatComMemoria(tamanho_janela=4, limite_maximo=400)
    
    print("Configura√ß√£o otimizada:")
    print("  ‚Ä¢ Sliding Window: 4 pares (8 mensagens)")
    print("  ‚Ä¢ Monitoramento: 400 tokens")
    print("\nEsta √© a configura√ß√£o recomendada para uso geral!\n")
    print("-"*60 + "\n")
    
    # Simula conversa longa
    perguntas = [
        "O que √© aprendizado de m√°quina?",
        "Quais s√£o os tipos principais?",
        "Explique aprendizado supervisionado",
        "E o n√£o supervisionado?",
        "O que √© deep learning?",
        "Como funciona uma rede neural?",
    ]
    
    for i, pergunta in enumerate(perguntas, 1):
        print(f"\n{'='*60}")
        print(f"INTERA√á√ÉO {i}")
        print('='*60)
        print(f"Voc√™: {pergunta}\n")
        
        resposta = chat.enviar_mensagem(pergunta)
        print(f"Assistente: {resposta[:150]}...\n")
    
    print("\n" + "="*60)
    print("RESULTADO FINAL:")
    print("="*60 + "\n")
    
    chat.debug_memoria()
    chat.grafico_tokens()
    
    print("BENEF√çCIOS DO SISTEMA COMPLETO:")
    print("  ‚úì Sliding window mant√©m mem√≥ria controlada")
    print("  ‚úì Monitoramento alerta sobre uso de tokens")
    print("  ‚úì Custos previs√≠veis e controlados")
    print("  ‚úì Contexto relevante sempre dispon√≠vel")
    print("  ‚úì Sem necessidade de interven√ß√£o manual\n")


def exemplo_modo_debug():
    """Demonstra o modo debug com logging detalhado"""
    
    print("\n" + "="*60)
    print("EXEMPLO: MODO DEBUG COM LOGGING")
    print("="*60 + "\n")
    
    # Cria chat com modo debug ativo
    chat = ChatComMemoria(
        tamanho_janela=3,
        limite_maximo=300,
        modo_debug=True
    )
    
    print("Modo Debug ATIVO")
    print(f"Arquivo de log: {chat.arquivo_log}\n")
    print("-"*60 + "\n")
    
    # Envia algumas mensagens
    print("Enviando mensagens para gerar log...\n")
    
    chat.enviar_mensagem("Ol√°! Como voc√™ est√°?")
    chat.enviar_mensagem("Me explique o que √© uma lista em Python")
    chat.enviar_mensagem("E um dicion√°rio?")
    
    print("\n" + "-"*60)
    print("\nConversa√ß√£o conclu√≠da!")
    print(f"\nVerifique o arquivo de log para ver detalhes completos:")
    print(f"  üìÑ {chat.arquivo_log}\n")
    
    chat.debug_memoria()
    
    print("O QUE O LOG CONT√âM:")
    print("  ‚Ä¢ Timestamp de cada intera√ß√£o")
    print("  ‚Ä¢ Mensagem do usu√°rio")
    print("  ‚Ä¢ System prompt utilizado")
    print("  ‚Ä¢ Par√¢metros do modelo (temperature, max_tokens, etc)")
    print("  ‚Ä¢ Hist√≥rico completo antes da nova mensagem")
    print("  ‚Ä¢ Resposta do assistente")
    print("  ‚Ä¢ Status de mem√≥ria (tokens, janela, alertas)")
    print("  ‚Ä¢ A√ß√µes executadas (sliding window, limpeza, etc)")
    print("\n√öTIL PARA:")
    print("  ‚Ä¢ Debugging de problemas")
    print("  ‚Ä¢ Auditoria de conversas")
    print("  ‚Ä¢ Aprendizado sobre gerenciamento de mem√≥ria")
    print("  ‚Ä¢ An√°lise de custos e uso de tokens\n")


def exemplo_base_url_customizada():
    """Demonstra uso de URL customizada para provedores alternativos"""
    
    print("\n" + "="*60)
    print("EXEMPLO: URL CUSTOMIZADA (PROVEDORES ALTERNATIVOS)")
    print("="*60 + "\n")
    
    print("Este exemplo demonstra como configurar URLs customizadas")
    print("para usar provedores compat√≠veis com o padr√£o OpenAI.\n")
    
    print("CASOS DE USO COMUNS:\n")
    
    print("1. Azure OpenAI Service")
    print("   .env:")
    print("   OPENAI_BASE_URL=https://seu-recurso.openai.azure.com")
    print("   OPENAI_API_KEY=sua-chave-azure")
    print("   OPENAI_MODEL=gpt-4o-mini\n")
    
    print("2. Ollama (modelos locais)")
    print("   .env:")
    print("   OPENAI_BASE_URL=http://localhost:11434/v1")
    print("   OPENAI_API_KEY=ollama")
    print("   OPENAI_MODEL=llama2\n")
    
    print("3. LM Studio (desenvolvimento local)")
    print("   .env:")
    print("   OPENAI_BASE_URL=http://localhost:1234/v1")
    print("   OPENAI_API_KEY=lm-studio")
    print("   OPENAI_MODEL=local-model\n")
    
    print("-"*60)
    print("\nCOMO FUNCIONA:")
    print("- Se OPENAI_BASE_URL n√£o estiver configurada ‚Üí OpenAI padr√£o")
    print("- Se OPENAI_BASE_URL estiver configurada ‚Üí Provedor customizado")
    print("- A URL deve come√ßar com http:// ou https://")
    print("- A maioria dos provedores requer /v1 no final da URL\n")
    
    print("-"*60)
    print("\nVANTAGENS:")
    print("‚úì Testar modelos locais sem custo")
    print("‚úì Usar Azure OpenAI em ambientes corporativos")
    print("‚úì Compatibilidade com m√∫ltiplos provedores")
    print("‚úì Mesma interface de c√≥digo para diferentes backends\n")
    
    print("-"*60)
    print("\nPASSOS PARA USAR:")
    print("1. Configure o provedor desejado (Ollama, LM Studio, etc)")
    print("2. Adicione OPENAI_BASE_URL no arquivo .env")
    print("3. Ajuste OPENAI_MODEL para o modelo dispon√≠vel")
    print("4. Execute normalmente - o c√≥digo se adapta automaticamente\n")
    
    print("="*60)
    print("Nota: Este exemplo √© informativo. Para usar,")
    print("configure as vari√°veis no .env e execute o chat normalmente.")
    print("="*60 + "\n")


def menu_exemplos():
    """Menu interativo para escolher exemplos"""
    
    exemplos = {
        "1": ("M√∫ltiplas Personalidades", exemplo_multiplas_personalidades),
        "2": ("Controle de Contexto", exemplo_controle_contexto),
        "3": ("Conversa Longa", exemplo_conversa_longa),
        "4": ("Tratamento de Erros", exemplo_tratamento_erros),
        "5": ("An√°lise de C√≥digo", exemplo_analise_codigo),
        "6": ("Sliding Window", exemplo_janela_deslizante),
        "7": ("Monitoramento Autom√°tico", exemplo_monitoramento_automatico),
        "8": ("Sistema Completo", exemplo_sistema_completo),
        "9": ("Modo Debug", exemplo_modo_debug),
        "10": ("URL Customizada", exemplo_base_url_customizada),
        "11": ("Executar Todos", lambda: None)
    }
    
    print("\n" + "="*60)
    print("EXEMPLOS AVAN√áADOS - CHAT OPENAI")
    print("="*60)
    
    for key, (nome, _) in exemplos.items():
        print(f"{key}. {nome}")
    
    print("0. Sair")
    print("="*60)
    
    while True:
        escolha = input("\nEscolha um exemplo: ").strip()
        
        if escolha == "0":
            print("Encerrando...")
            break
        
        if escolha == "11":
            print("\nExecutando todos os exemplos...\n")
            for key in ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]:
                exemplos[key][1]()
                time.sleep(2)
            print("\nTodos os exemplos executados!")
            break
        
        if escolha in exemplos and escolha != "11":
            try:
                exemplos[escolha][1]()
                input("\nPressione Enter para continuar...")
            except Exception as e:
                print(f"\nErro ao executar exemplo: {e}")
        else:
            print("Op√ß√£o inv√°lida")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # Executa exemplo espec√≠fico via argumento
        exemplo_map = {
            "--personalidades": exemplo_multiplas_personalidades,
            "--contexto": exemplo_controle_contexto,
            "--longa": exemplo_conversa_longa,
            "--erros": exemplo_tratamento_erros,
            "--analise": exemplo_analise_codigo,
            "--janela": exemplo_janela_deslizante,
            "--monitoramento": exemplo_monitoramento_automatico,
            "--completo": exemplo_sistema_completo,
            "--debug": exemplo_modo_debug,
            "--baseurl": exemplo_base_url_customizada,
            "--todos": lambda: [
                exemplo_multiplas_personalidades(),
                exemplo_controle_contexto(),
                exemplo_conversa_longa(),
                exemplo_tratamento_erros(),
                exemplo_analise_codigo(),
                exemplo_janela_deslizante(),
                exemplo_monitoramento_automatico(),
                exemplo_sistema_completo(),
                exemplo_modo_debug(),
                exemplo_base_url_customizada()
            ]
        }
        
        arg = sys.argv[1]
        if arg in exemplo_map:
            exemplo_map[arg]()
        else:
            print(f"Argumento inv√°lido: {arg}")
            print("Argumentos dispon√≠veis:", ", ".join(exemplo_map.keys()))
    else:
        # Modo interativo
        menu_exemplos()

