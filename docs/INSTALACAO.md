# üì¶ Instala√ß√£o

Guia completo para configurar o ambiente e executar o chat com mem√≥ria.

## √çndice

- [Pr√©-requisitos](#pr√©-requisitos)
- [Passo 1: Instalar o Miniconda](#passo-1-instalar-o-miniconda)
- [Passo 2: Criar Ambiente Conda](#passo-2-criar-ambiente-conda)
- [Passo 3: Instalar Depend√™ncias](#passo-3-instalar-depend√™ncias)
- [Passo 4: Configurar Vari√°veis de Ambiente](#passo-4-configurar-vari√°veis-de-ambiente)
- [Passo 5: Verificar Instala√ß√£o](#passo-5-verificar-instala√ß√£o)

---

## Pr√©-requisitos

- Sistema operacional: Windows, Linux ou macOS
- Conta na OpenAI com API key ativa ([criar conta aqui](https://platform.openai.com/signup))
- Conhecimento b√°sico de linha de comando

---

## Passo 1: Instalar o Miniconda

O Miniconda √© uma vers√£o m√≠nima do Anaconda que permite gerenciar ambientes Python isolados.

### Download

Acesse o site oficial e baixe o instalador para seu sistema:

**üîó [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)**

### Instala√ß√£o por Sistema Operacional

#### Windows

1. Execute o instalador `.exe` baixado
2. Siga o assistente de instala√ß√£o
3. ‚úÖ Marque a op√ß√£o "Add Miniconda3 to PATH" (recomendado)
4. Conclua a instala√ß√£o
5. Abra o **Anaconda Prompt** ou **CMD/PowerShell**

#### Linux/macOS

```bash
# Ap√≥s baixar o instalador .sh
chmod +x Miniconda3-latest-Linux-x86_64.sh  # ou macOS equivalente
./Miniconda3-latest-Linux-x86_64.sh

# Siga as instru√ß√µes no terminal
# Aceite a licen√ßa e confirme a localiza√ß√£o da instala√ß√£o
```

### Verificar Instala√ß√£o

```bash
conda --version
# Sa√≠da esperada: conda 24.x.x (ou similar)
```

---

## Passo 2: Criar Ambiente Conda

Crie um ambiente isolado para o projeto:

```bash
# Criar ambiente com Python 3.11
conda create -n chat_memoria python=3.11 -y

# Ativar o ambiente
conda activate chat_memoria
```

**üìå Nota:** Voc√™ precisar√° ativar o ambiente sempre que for usar o projeto:
```bash
conda activate chat_memoria
```

---

## Passo 3: Instalar Depend√™ncias

Navegue at√© a pasta do projeto e instale as bibliotecas necess√°rias:

```bash
# Navegar para o diret√≥rio do projeto
cd c:\python_projects\exemplo_chat_memoria  # Windows
# ou
cd ~/python_projects/exemplo_chat_memoria   # Linux/macOS

# Instalar depend√™ncias
pip install -r requirements.txt
```

### Depend√™ncias Instaladas

O projeto usa duas bibliotecas principais:

- **openai** (>=1.12.0): Cliente oficial da API OpenAI
- **python-dotenv** (>=1.0.0): Carregamento de vari√°veis de ambiente

---

## Passo 4: Configurar Vari√°veis de Ambiente

### 4.1 Criar Arquivo .env

Crie um arquivo chamado `.env` na raiz do projeto:

```bash
# Windows (PowerShell)
New-Item .env -ItemType File

# Linux/macOS
touch .env
```

### 4.2 Adicionar Configura√ß√µes

Edite o arquivo `.env` e adicione as seguintes vari√°veis:

```env
# API Key da OpenAI (obrigat√≥rio)
OPENAI_API_KEY=sk-proj-sua_chave_aqui

# Modelo a ser usado (obrigat√≥rio)
OPENAI_MODEL=gpt-4o-mini

# Temperatura - controla criatividade (obrigat√≥rio: 0.0 a 2.0)
OPENAI_TEMPERATURE=0.7

# M√°ximo de tokens na resposta (obrigat√≥rio: inteiro positivo)
OPENAI_MAX_TOKENS=1000
```

### 4.3 Detalhamento das Vari√°veis

#### OPENAI_API_KEY

- **Obrigat√≥rio:** Sim
- **Formato:** String come√ßando com `sk-` ou `sk-proj-`
- **Onde obter:** [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
- **Exemplo:** `sk-proj-abc123def456...`

‚ö†Ô∏è **Seguran√ßa:** Nunca compartilhe sua API key ou fa√ßa commit dela no Git!

#### OPENAI_MODEL

- **Obrigat√≥rio:** Sim
- **Valores comuns:**
  - `gpt-4o-mini` - R√°pido e econ√¥mico (recomendado)
  - `gpt-4o` - Mais poderoso, mais caro
  - `gpt-3.5-turbo` - Alternativa mais antiga
- **Exemplo:** `gpt-4o-mini`

#### OPENAI_TEMPERATURE

- **Obrigat√≥rio:** Sim
- **Formato:** N√∫mero decimal entre 0.0 e 2.0
- **Valores:**
  - `0.0` - Respostas determin√≠sticas e focadas
  - `0.7` - Balanceado (recomendado para uso geral)
  - `1.0` - Mais criativo
  - `2.0` - M√°xima aleatoriedade
- **Exemplo:** `0.7`

#### OPENAI_MAX_TOKENS

- **Obrigat√≥rio:** Sim
- **Formato:** N√∫mero inteiro positivo (> 0)
- **Descri√ß√£o:** Limita o tamanho m√°ximo da resposta
- **Valores sugeridos:**
  - `500` - Respostas curtas
  - `1000` - Respostas m√©dias (recomendado)
  - `2000` - Respostas longas
- **Exemplo:** `1000`

#### OPENAI_BASE_URL

- **Obrigat√≥rio:** N√£o
- **Formato:** URL completa come√ßando com `http://` ou `https://`
- **Descri√ß√£o:** URL base customizada para conectar a provedores compat√≠veis com o padr√£o OpenAI
- **Quando usar:**
  - **Azure OpenAI Service** - Usar endpoint do seu recurso Azure
  - **Ollama** - Executar modelos localmente
  - **LM Studio** - Testar modelos locais
  - **Outros provedores** - Qualquer servi√ßo compat√≠vel com API OpenAI
- **Se n√£o configurada:** Usa o endpoint padr√£o da OpenAI (`https://api.openai.com/v1`)
- **Exemplos:**
  - Azure: `https://seu-recurso.openai.azure.com`
  - Ollama: `http://localhost:11434/v1`
  - LM Studio: `http://localhost:1234/v1`

**Casos de uso comuns:**

1. **Azure OpenAI Service**
   ```env
   OPENAI_BASE_URL=https://seu-recurso.openai.azure.com
   OPENAI_API_KEY=sua-chave-azure
   OPENAI_MODEL=gpt-4o-mini  # ou modelo dispon√≠vel no Azure
   ```

2. **Ollama (modelos locais)**
   ```env
   OPENAI_BASE_URL=http://localhost:11434/v1
   OPENAI_API_KEY=ollama  # Ollama n√£o valida a key, mas √© obrigat√≥ria
   OPENAI_MODEL=llama2  # ou outro modelo instalado no Ollama
   ```

3. **LM Studio (desenvolvimento local)**
   ```env
   OPENAI_BASE_URL=http://localhost:1234/v1
   OPENAI_API_KEY=lm-studio  # LM Studio n√£o valida, mas √© obrigat√≥ria
   OPENAI_MODEL=local-model  # modelo carregado no LM Studio
   ```

‚ö†Ô∏è **Importante:** 
- A URL deve terminar com `/v1` para a maioria dos provedores
- Verifique a documenta√ß√£o do seu provedor para detalhes espec√≠ficos
- Para servi√ßos locais (Ollama, LM Studio), certifique-se de que o servidor est√° rodando

### 4.4 Valida√ß√£o Manual

Ap√≥s criar o `.env`, verifique:

‚úÖ Arquivo est√° na raiz do projeto (mesmo diret√≥rio de `chat_openai_memoria.py`)  
‚úÖ API key est√° no formato correto  
‚úÖ Temperature est√° entre 0.0 e 2.0  
‚úÖ Max tokens √© um n√∫mero inteiro positivo  
‚úÖ Base URL (se configurada) come√ßa com http:// ou https://  
‚úÖ N√£o h√° espa√ßos antes ou depois do `=`  

---

## Passo 5: Verificar Instala√ß√£o

### 5.1 Teste B√°sico

Execute o chat para verificar se tudo est√° funcionando:

```bash
python chat_openai_memoria.py
```

**Sa√≠da esperada:**

```
=== Configura√ß√£o do Chat ===
Modelo: gpt-4o-mini
Temperatura: 0.7
Max Tokens: 1000
============================

Chat com Mem√≥ria - Digite 'sair' para encerrar
Voc√™: 
```

### 5.2 Teste de API

Digite uma mensagem simples para testar a conex√£o com a API:

```
Voc√™: Ol√°, voc√™ est√° funcionando?
```

Se receber uma resposta do assistente, a instala√ß√£o est√° completa! ‚úÖ

### 5.3 Solu√ß√£o de Problemas

Se encontrar erros, consulte o [TROUBLESHOOTING.md](TROUBLESHOOTING.md) para solu√ß√µes.

#### Erros Comuns

| Erro | Causa Prov√°vel |
|------|----------------|
| `Arquivo .env n√£o encontrado` | Arquivo .env n√£o existe ou est√° no local errado |
| `OPENAI_API_KEY n√£o encontrada` | Vari√°vel n√£o definida no .env |
| `OPENAI_TEMPERATURE deve estar entre 0.0 e 2.0` | Valor inv√°lido para temperature |
| `OPENAI_MAX_TOKENS deve ser um n√∫mero inteiro positivo` | Valor inv√°lido para max_tokens |
| `OPENAI_BASE_URL inv√°lida` | URL n√£o come√ßa com http:// ou https:// |
| `AuthenticationError` | API key inv√°lida ou expirada |

---

## Pr√≥ximos Passos

Ap√≥s a instala√ß√£o bem-sucedida:

1. üìö Leia [CONCEITOS.md](CONCEITOS.md) para entender como funciona a mem√≥ria conversacional
2. üöÄ Consulte [USO_BASICO.md](USO_BASICO.md) para aprender os comandos e modos de uso
3. ‚ö° Explore [EXEMPLOS_AVANCADOS.md](EXEMPLOS_AVANCADOS.md) para t√©cnicas avan√ßadas

---

## Desinstala√ß√£o

Para remover o ambiente:

```bash
# Desativar ambiente
conda deactivate

# Remover ambiente
conda env remove -n chat_memoria
```
