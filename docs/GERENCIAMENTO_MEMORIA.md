# ğŸ§  Gerenciamento de MemÃ³ria

EstratÃ©gias para controlar custos e otimizar o uso de memÃ³ria conversacional.

## Ãndice

- [Por que Gerenciar MemÃ³ria?](#por-que-gerenciar-memÃ³ria)
- [EstratÃ©gia 1: Limpeza Manual](#estratÃ©gia-1-limpeza-manual)
- [EstratÃ©gia 2: Sliding Window](#estratÃ©gia-2-sliding-window)
- [EstratÃ©gia 3: Monitoramento de Tokens](#estratÃ©gia-3-monitoramento-de-tokens)
- [Sistema Completo (Recomendado)](#sistema-completo-recomendado)
- [Modo Debug](#modo-debug)
- [ComparaÃ§Ã£o de EstratÃ©gias](#comparaÃ§Ã£o-de-estratÃ©gias)
- [Ferramentas de DiagnÃ³stico](#ferramentas-de-diagnÃ³stico)

---

## Por que Gerenciar MemÃ³ria?

### O Problema do Crescimento

```
RequisiÃ§Ã£o 1:
+-----------+
| 100 tokens|  Custo: $0.001
+-----------+

RequisiÃ§Ã£o 5:
+-----------+
| 500 tokens|  Custo: $0.005
+-----------+

RequisiÃ§Ã£o 10:
+------------+
| 1000 tokens|  Custo: $0.010
+------------+

RequisiÃ§Ã£o 20:
+------------+
| 2000 tokens|  Custo: $0.020
+------------+

Sem gerenciamento: Custo cresce linearmente!
```

### Impacto em Custos

**Exemplo de conversa longa (30 interaÃ§Ãµes sem gerenciamento):**

```
InteraÃ§Ã£o 1:  100 tokens  â†’  $0.001
InteraÃ§Ã£o 5:  500 tokens  â†’  $0.005
InteraÃ§Ã£o 10: 1000 tokens â†’  $0.010
InteraÃ§Ã£o 15: 1500 tokens â†’  $0.015
InteraÃ§Ã£o 20: 2000 tokens â†’  $0.020
InteraÃ§Ã£o 25: 2500 tokens â†’  $0.025
InteraÃ§Ã£o 30: 3000 tokens â†’  $0.030

Custo total: ~$0.35 para 30 mensagens
```

**Com gerenciamento (sliding window de 8 pares):**

```
InteraÃ§Ã£o 1:  100 tokens  â†’  $0.001
InteraÃ§Ã£o 5:  400 tokens  â†’  $0.004
InteraÃ§Ã£o 10: 400 tokens  â†’  $0.004
InteraÃ§Ã£o 15: 400 tokens  â†’  $0.004
InteraÃ§Ã£o 20: 400 tokens  â†’  $0.004
InteraÃ§Ã£o 25: 400 tokens  â†’  $0.004
InteraÃ§Ã£o 30: 400 tokens  â†’  $0.004

Custo total: ~$0.12 para 30 mensagens

Economia: 66% de reduÃ§Ã£o!
```

### Outros Problemas

âŒ **LentidÃ£o:** Mais tokens = mais tempo de processamento  
âŒ **Limite de modelo:** Modelos tÃªm limite mÃ¡ximo de tokens  
âŒ **Contexto irrelevante:** InformaÃ§Ãµes antigas podem confundir  
âŒ **Perda de foco:** TÃ³picos distantes diluem atenÃ§Ã£o do modelo  

---

## EstratÃ©gia 1: Limpeza Manual

### O que Ã©?

Usar o comando `/limpar` ou mÃ©todo `limpar_historico()` para **zerar a memÃ³ria** quando apropriado.

### Diagrama

```
Estado Inicial:
+------------------+
| Msg 1            |
| Msg 2            |
| Msg 3            |
| Msg 4            |
+------------------+
   4000 tokens
        |
        | /limpar
        v
+------------------+
|    (vazio)       |
+------------------+
     0 tokens
        |
        | Nova conversa
        v
+------------------+
| Msg 5            |
| Msg 6            |
+------------------+
   300 tokens
```

### Quando Usar

âœ… **Limpar quando:**
- Mudar completamente de assunto
- Cliente/sessÃ£o diferente
- Atingir limite de custos desejado
- Contexto anterior nÃ£o Ã© mais necessÃ¡rio
- ComeÃ§ar anÃ¡lise de novo documento/cÃ³digo

âŒ **NÃƒO limpar quando:**
- Perguntas relacionadas ao contexto
- AnÃ¡lise incremental em andamento
- Continuidade Ã© importante

### CÃ³digo Exemplo

```python
from chat_openai_memoria import ChatComMemoria

chat = ChatComMemoria()

# SessÃ£o 1
chat.enviar_mensagem("Analise este cÃ³digo Python: ...")
chat.enviar_mensagem("Quais sÃ£o os problemas?")
chat.enviar_mensagem("Como melhorar?")

print(f"Tokens sessÃ£o 1: {chat.contar_tokens_aproximado()}")

# Finalizar sessÃ£o 1, comeÃ§ar sessÃ£o 2
chat.limpar_historico()

# SessÃ£o 2 (independente)
chat.enviar_mensagem("Explique JavaScript closures")
print(f"Tokens sessÃ£o 2: {chat.contar_tokens_aproximado()}")
```

### Modo Interativo

```bash
$ python chat_openai_memoria.py

VocÃª: Explique Python
Assistente: Python Ã© uma linguagem...

VocÃª: /limpar
HistÃ³rico limpo - memÃ³ria apagada

VocÃª: Agora explique JavaScript
Assistente: JavaScript Ã© uma linguagem...
```

### Vantagens e Desvantagens

| Vantagens | Desvantagens |
|-----------|--------------|
| âœ… Simples de implementar | âŒ Perde TODO o contexto |
| âœ… ReduÃ§Ã£o mÃ¡xima de custos | âŒ DecisÃ£o manual |
| âœ… Controle total | âŒ Pode limpar cedo demais |

---

## EstratÃ©gia 2: Sliding Window

### O que Ã©?

Manter apenas as **N pares de mensagens mais recentes** (user + assistant), descartando automaticamente as antigas. Esta estratÃ©gia estÃ¡ **implementada nativamente** na classe `ChatComMemoria`.

### Diagrama Detalhado

```
Janela de 3 pares (6 mensagens):

Passo 1: Conversa normal (dentro da janela)
+-----+-----+-----+-----+-----+-----+
| U1  | A1  | U2  | A2  | U3  | A3  |
+-----+-----+-----+-----+-----+-----+
[          Janela Atual          ]
Tokens: 400

Passo 2: Adiciona U4 e A4 (excede janela)
+-----+-----+-----+-----+-----+-----+-----+-----+
| U1  | A1  | U2  | A2  | U3  | A3  | U4  | A4  |
+-----+-----+-----+-----+-----+-----+-----+-----+
 [XX]  [XX]        [    Janela Atual     ]
Remove U1 e A1
Tokens: 400 (estÃ¡vel)

Passo 3: Adiciona U5 e A5
+-----+-----+-----+-----+-----+-----+-----+-----+
| U2  | A2  | U3  | A3  | U4  | A4  | U5  | A5  |
+-----+-----+-----+-----+-----+-----+-----+-----+
 [XX]  [XX]        [    Janela Atual       ]
Remove U2 e A2
Tokens: 400 (estÃ¡vel)
```

### ConfiguraÃ§Ã£o

**OpÃ§Ã£o 1: Via `.env` (Recomendado)**

```env
# No arquivo .env
JANELA_MAX=8  # MantÃ©m 8 pares (16 mensagens)
```

**OpÃ§Ã£o 2: Via Construtor**

```python
from chat_openai_memoria import ChatComMemoria

# Janela de 6 pares (12 mensagens)
chat = ChatComMemoria(tamanho_janela=6)

# Conversa longa - janela aplicada automaticamente
for i in range(20):
    resposta = chat.enviar_mensagem(f"Pergunta {i+1}")
    print(f"Mensagens mantidas: {len(chat.historico)}")
```

**OpÃ§Ã£o 3: Ambas (`.env` como padrÃ£o)**

```python
# .env tem JANELA_MAX=10
chat1 = ChatComMemoria()  # Usa 10 do .env

# Sobrescreve com parÃ¢metro
chat2 = ChatComMemoria(tamanho_janela=5)  # Usa 5
```

### Escolhendo o Tamanho da Janela

```
Janela Pequena (2-4 pares):
+------------------+
| Contexto: MÃ­nimo |
| Mensagens: 4-8   |
| Tokens: 100-300  |
| Custo: Muito baixo|
+------------------+
Uso: FAQ, respostas rÃ¡pidas

Janela MÃ©dia (6-8 pares):
+------------------+
| Contexto: Adequado|
| Mensagens: 12-16 |
| Tokens: 300-600  |
| Custo: Baixo     |
+------------------+
Uso: Conversas gerais (recomendado)

Janela Grande (10-16 pares):
+------------------+
| Contexto: Amplo  |
| Mensagens: 20-32 |
| Tokens: 600-1200 |
| Custo: MÃ©dio     |
+------------------+
Uso: AnÃ¡lises complexas, tutoriais
```

### Exemplo PrÃ¡tico

```python
from chat_openai_memoria import ChatComMemoria

# Configurar janela de 3 pares
chat = ChatComMemoria(tamanho_janela=3)

# Enviar 5 perguntas
perguntas = [
    "Qual Ã© a capital da FranÃ§a?",
    "E da Alemanha?",
    "E da ItÃ¡lia?",
    "E da Espanha?",
    "E de Portugal?",
]

for i, pergunta in enumerate(perguntas, 1):
    print(f"\n[Pergunta {i}] {pergunta}")
    chat.enviar_mensagem(pergunta)
    print(f"Mensagens no histÃ³rico: {len(chat.historico)}")

# Resultado:
# Pergunta 1: 2 mensagens (U1, A1)
# Pergunta 2: 4 mensagens (U1, A1, U2, A2)
# Pergunta 3: 6 mensagens (U1, A1, U2, A2, U3, A3)
# Pergunta 4: 6 mensagens (U2, A2, U3, A3, U4, A4) <- U1,A1 removidos
# Pergunta 5: 6 mensagens (U3, A3, U4, A4, U5, A5) <- U2,A2 removidos
```

### Vantagens e Desvantagens

| Vantagens | Desvantagens |
|-----------|--------------|
| âœ… Custos previsÃ­veis e estÃ¡veis | âŒ Perde contexto antigo |
| âœ… Completamente automÃ¡tico | âŒ Pode cortar no meio de anÃ¡lise |
| âœ… Escala bem para conversas longas | âŒ ConfiguraÃ§Ã£o do tamanho Ã© crÃ­tica |
| âœ… FÃ¡cil de configurar | âŒ NÃ£o diferencia contexto importante |

---

## EstratÃ©gia 3: Monitoramento de Tokens

### O que Ã©?

**Monitorar ativamente** o nÃºmero de tokens e **alertar** quando atingir nÃ­veis crÃ­ticos. Os nÃ­veis sÃ£o calculados automaticamente baseado no limite mÃ¡ximo configurado. Esta estratÃ©gia estÃ¡ **implementada nativamente** na classe `ChatComMemoria`.

### Diagrama de NÃ­veis

```
NÃ­veis AutomÃ¡ticos (baseado em LIMITE_MAXIMO):

ğŸŸ¢ Verde (0-33%):
+------------------+
| Uso normal       |
| Sem aÃ§Ã£o         |
+------------------+

ğŸŸ¡ Amarelo (33-66%):
+------------------+
| AtenÃ§Ã£o          |
| ComeÃ§ando alto   |
+------------------+

ğŸŸ  Laranja (66-99%):
+------------------+
| Alerta elevado   |
| PrÃ³ximo do limite|
+------------------+

ğŸ”´ Vermelho (â‰¥100%):
+------------------+
| CRÃTICO          |
| AÃ§Ã£o recomendada |
+------------------+
```

### ConfiguraÃ§Ã£o

**OpÃ§Ã£o 1: Via `.env` (Recomendado)**

```env
# No arquivo .env
LIMITE_MAXIMO=1000  # Os nÃ­veis serÃ£o calculados automaticamente:
                    # ğŸŸ¢ 0-333 tokens
                    # ğŸŸ¡ 333-666 tokens
                    # ğŸŸ  666-999 tokens
                    # ğŸ”´ â‰¥1000 tokens
```

**OpÃ§Ã£o 2: Via Construtor**

```python
from chat_openai_memoria import ChatComMemoria

# Limite de 500 tokens
chat = ChatComMemoria(limite_maximo=500)

# NÃ­veis calculados automaticamente:
# ğŸŸ¢ 0-166 tokens (0-33%)
# ğŸŸ¡ 166-333 tokens (33-66%)
# ğŸŸ  333-500 tokens (66-99%)
# ğŸ”´ â‰¥500 tokens (â‰¥100%)
```

### Como Funciona

Ao atingir cada nÃ­vel, o sistema exibe alertas **automaticamente** apÃ³s cada `enviar_mensagem()`:

```python
chat = ChatComMemoria(limite_maximo=300)

# Primeiras mensagens - nÃ­vel verde
chat.enviar_mensagem("Pergunta curta")
# SaÃ­da: (nenhum alerta)

# Conversando mais - nÃ­vel amarelo
chat.enviar_mensagem("Outra pergunta")
# SaÃ­da: âš ï¸  ğŸŸ¡ AMARELO: 150 tokens (50.0% do limite)

# Mais mensagens - nÃ­vel laranja
chat.enviar_mensagem("Mais uma pergunta longa...")
# SaÃ­da: âš ï¸  ğŸŸ  LARANJA: 240 tokens (80.0% do limite)
#        âš ï¸     AtenÃ§Ã£o: Aproximando do limite mÃ¡ximo

# Atingiu o limite - nÃ­vel vermelho
chat.enviar_mensagem("Ãšltima pergunta bem longa...")
# SaÃ­da: âš ï¸  ğŸ”´ CRÃTICO: 320 tokens (106.7% do limite)
#        âš ï¸     AÃ§Ã£o recomendada: Execute limpar_historico() ou ajuste JANELA_MAX no .env
```

### AÃ§Ã£o no NÃ­vel Vermelho

Quando o limite Ã© atingido, o sistema **recomenda** (mas nÃ£o forÃ§a) aÃ§Ãµes:

```
ğŸ”´ CRÃTICO: VocÃª tem 3 opÃ§Ãµes:

1. Limpeza Manual:
   chat.limpar_historico()
   
2. Ajustar Sliding Window:
   # No .env
   JANELA_MAX=6  # Reduzir janela
   
3. Aumentar Limite:
   # No .env
   LIMITE_MAXIMO=1500  # Se apropriado
```

### Exemplo PrÃ¡tico

```python
from chat_openai_memoria import ChatComMemoria

# Limite baixo para demonstraÃ§Ã£o
chat = ChatComMemoria(limite_maximo=300, modo_debug=False)

perguntas = [
    "Me explique o que Ã© Python em poucas palavras.",
    "Quais sÃ£o os principais tipos de dados em Python?",
    "Como funcionam as listas em Python?",
    "Explique o conceito de dicionÃ¡rios em Python.",
]

for i, pergunta in enumerate(perguntas, 1):
    print(f"\n{'='*60}")
    print(f"PERGUNTA {i}")
    print('='*60)
    print(pergunta)
    chat.enviar_mensagem(pergunta)
    # Alertas aparecem automaticamente aqui
```

**SaÃ­da:**

```
============================================================
PERGUNTA 1
============================================================
Me explique o que Ã© Python em poucas palavras.
Assistente: Python Ã© uma linguagem...
(sem alerta - nÃ­vel verde)

============================================================
PERGUNTA 2
============================================================
Quais sÃ£o os principais tipos de dados em Python?
Assistente: Os principais tipos...

âš ï¸  ğŸŸ¡ AMARELO: 145 tokens (48.3% do limite)

============================================================
PERGUNTA 3
============================================================
Como funcionam as listas em Python?
Assistente: Listas sÃ£o estruturas...

âš ï¸  ğŸŸ  LARANJA: 230 tokens (76.7% do limite)
âš ï¸     AtenÃ§Ã£o: Aproximando do limite mÃ¡ximo

============================================================
PERGUNTA 4
============================================================
Explique o conceito de dicionÃ¡rios em Python.
Assistente: DicionÃ¡rios sÃ£o...

âš ï¸  ğŸ”´ CRÃTICO: 315 tokens (105.0% do limite)
âš ï¸     AÃ§Ã£o recomendada: Execute limpar_historico() ou ajuste JANELA_MAX no .env
```

### Valores Sugeridos

```
Conversas Curtas/EconÃ´micas:
LIMITE_MAXIMO=500-800
Uso: FAQ, suporte rÃ¡pido

Uso Geral (Recomendado):
LIMITE_MAXIMO=1000-1500
Uso: Conversas normais, tutoriais

Conversas Longas/Complexas:
LIMITE_MAXIMO=2000+
Uso: AnÃ¡lises profundas, sessÃµes extensas
```

### Vantagens e Desvantagens

| Vantagens | Desvantagens |
|-----------|--------------|
| âœ… Visibilidade clara de custos | âŒ Alertas podem interromper UX |
| âœ… NÃ­veis calculados automaticamente | âŒ NÃ£o toma aÃ§Ã£o automÃ¡tica |
| âœ… Previne custos excessivos | âŒ UsuÃ¡rio deve decidir aÃ§Ã£o |
| âœ… FÃ¡cil de configurar | âŒ Requer configuraÃ§Ã£o de limite |

---

## Sistema Completo (Recomendado)

### Combinando Sliding Window + Monitoramento

A **melhor prÃ¡tica** Ã© usar ambas estratÃ©gias juntas para controle automÃ¡tico e visibilidade:

```python
from chat_openai_memoria import ChatComMemoria

# Sistema completo configurado
chat = ChatComMemoria(
    tamanho_janela=8,     # MantÃ©m 8 pares (16 mensagens)
    limite_maximo=1000    # Alerta ao aproximar de 1000 tokens
)

# BenefÃ­cios:
# âœ… Sliding window mantÃ©m memÃ³ria controlada automaticamente
# âœ… Monitoramento alerta sobre uso mesmo dentro da janela
# âœ… Custos previsÃ­veis
# âœ… Contexto relevante sempre disponÃ­vel
```

### ConfiguraÃ§Ã£o via `.env` (Recomendado)

```env
# arquivo .env
OPENAI_API_KEY=sua-chave-aqui
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000

# Gerenciamento de memÃ³ria
JANELA_MAX=8
LIMITE_MAXIMO=1000
```

```python
# CÃ³digo Python
from chat_openai_memoria import ChatComMemoria

# Carrega tudo do .env automaticamente
chat = ChatComMemoria()

# Pronto para uso com gerenciamento completo!
```

### Como as EstratÃ©gias Trabalham Juntas

```
Fluxo de uma Mensagem:

1. UsuÃ¡rio envia mensagem
2. API processa e retorna resposta
3. Resposta adicionada ao histÃ³rico
4. 
   â†“
5. SLIDING WINDOW verifica:
   - HistÃ³rico > janela_max?
   - Se SIM: Remove mensagens antigas
   - Se NÃƒO: MantÃ©m todas
   â†“
6. MONITORAMENTO verifica:
   - Calcula tokens atuais
   - Calcula percentual do limite
   - Exibe alerta apropriado (ğŸŸ¢ğŸŸ¡ğŸŸ ğŸ”´)
   â†“
7. Retorna resposta ao usuÃ¡rio
```

### Exemplo PrÃ¡tico Completo

```python
from chat_openai_memoria import ChatComMemoria

# ConfiguraÃ§Ã£o otimizada para uso geral
chat = ChatComMemoria(
    tamanho_janela=6,
    limite_maximo=600
)

print("Sistema completo ativo:")
print(f"  â€¢ Janela: {chat.tamanho_janela} pares")
print(f"  â€¢ Limite: {chat.limite_maximo} tokens\n")

# Simula conversa longa
perguntas = [
    "O que Ã© aprendizado de mÃ¡quina?",
    "Quais sÃ£o os tipos principais?",
    "Explique aprendizado supervisionado",
    "E o nÃ£o supervisionado?",
    "O que Ã© deep learning?",
    "Como funciona uma rede neural?",
    "Quais sÃ£o as aplicaÃ§Ãµes?",
    "Explique overfitting",
]

for i, pergunta in enumerate(perguntas, 1):
    print(f"\n{'='*60}")
    print(f"INTERAÃ‡ÃƒO {i}")
    print('='*60)
    print(f"VocÃª: {pergunta}\n")
    
    resposta = chat.enviar_mensagem(pergunta)
    print(f"Assistente: {resposta[:100]}...\n")
    
    # EstatÃ­sticas
    print(f"ğŸ“Š Status: {len(chat.historico)} mensagens, "
          f"{chat.contar_tokens_aproximado()} tokens")
```

**Comportamento Esperado:**

```
INTERAÃ‡ÃƒO 1:
VocÃª: O que Ã© aprendizado de mÃ¡quina?
Assistente: Aprendizado de mÃ¡quina Ã©...
ğŸ“Š Status: 2 mensagens, 85 tokens

INTERAÃ‡ÃƒO 4:
VocÃª: E o nÃ£o supervisionado?
Assistente: Aprendizado nÃ£o supervisionado...
ğŸ“Š Status: 8 mensagens, 340 tokens

INTERAÃ‡ÃƒO 7:
VocÃª: Quais sÃ£o as aplicaÃ§Ãµes?
Assistente: As aplicaÃ§Ãµes incluem...
ğŸ“Š Status: 12 mensagens, 510 tokens

âš ï¸  ğŸŸ  LARANJA: 510 tokens (85.0% do limite)
âš ï¸     AtenÃ§Ã£o: Aproximando do limite mÃ¡ximo
```

### CenÃ¡rios de Uso Recomendados

| CenÃ¡rio | Janela | Limite | Justificativa |
|---------|--------|--------|---------------|
| **Chatbot FAQ** | 3-4 | 400-600 | Perguntas independentes, contexto mÃ­nimo |
| **Tutor Interativo** | 6-8 | 800-1200 | EquilÃ­brio contexto/custo |
| **AnÃ¡lise de CÃ³digo** | 8-12 | 1500-2000 | Contexto amplo necessÃ¡rio |
| **Suporte TÃ©cnico** | 5-7 | 1000-1500 | SessÃµes mÃ©dias variÃ¡veis |

### Ajuste Fino

Se os alertas estÃ£o aparecendo muito:

```env
# OpÃ§Ã£o 1: Reduzir janela (menos contexto, menos tokens)
JANELA_MAX=5

# OpÃ§Ã£o 2: Aumentar limite (mais tolerÃ¢ncia)
LIMITE_MAXIMO=1500

# OpÃ§Ã£o 3: Ambos (balance customizado)
JANELA_MAX=7
LIMITE_MAXIMO=1200
```

---

## Modo Debug

### O que Ã©?

Modo que gera **logs detalhados** de cada interaÃ§Ã£o em arquivos timestampados na pasta `logs/`. Essencial para desenvolvimento, auditoria e aprendizado.

### Ativando

**OpÃ§Ã£o 1: Via `.env`**

```env
MODO_DEBUG=true
```

**OpÃ§Ã£o 2: Via Construtor**

```python
chat = ChatComMemoria(modo_debug=True)
```

### O que Ã© Registrado

Cada arquivo de log (`logs/chat_debug_YYYYMMDD_HHMMSS.log`) contÃ©m:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        CHAT DEBUG LOG                              â•‘
â•‘                   Chat OpenAI com MemÃ³ria                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SessÃ£o iniciada em: 17/12/2025 14:30:45
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIGURAÃ‡Ã•ES DA SESSÃƒO:
  â€¢ Modelo: gpt-4o-mini
  â€¢ Temperature: 0.7
  â€¢ Max Tokens: 1000
  â€¢ System Prompt: VocÃª Ã© um assistente Ãºtil e amigÃ¡vel.
  â€¢ Sliding Window: 8 pares de mensagens
  â€¢ Monitoramento: 1000 tokens (mÃ¡ximo)
    - ğŸŸ¢ Verde: 0-333 tokens (0-33%)
    - ğŸŸ¡ Amarelo: 333-666 tokens (33-66%)
    - ğŸŸ  Laranja: 666-1000 tokens (66-99%)
    - ğŸ”´ Vermelho: â‰¥1000 tokens (â‰¥100% - CRÃTICO)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  INTERAÃ‡ÃƒO #1                                                      â•‘
â•‘  17/12/2025 14:31:02                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[MENSAGEM DO USUÃRIO]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
O que Ã© Python?

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[SYSTEM PROMPT]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VocÃª Ã© um assistente Ãºtil e amigÃ¡vel.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[PARÃ‚METROS DO MODELO]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Modelo: gpt-4o-mini
  Temperature: 0.7
  Max Tokens: 1000

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[HISTÃ“RICO (antes da nova mensagem)]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total de mensagens: 0
  Tokens aproximados: 0

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[RESPOSTA DO ASSISTENTE]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel...

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[STATUS DE MEMÃ“RIA]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total de mensagens: 2
  Tokens aproximados: 65
  Janela mÃ¡xima: 16 mensagens (8 pares)
  Limite mÃ¡ximo: 1000 tokens
  Uso atual: 6.5% ğŸŸ¢

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Quando o Sliding Window Atua

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[AÃ‡Ã•ES EXECUTADAS]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âš ï¸  Sliding window aplicado: mantendo 8 pares de mensagens
```

### Quando Atinge NÃ­vel de Alerta

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[AÃ‡Ã•ES EXECUTADAS]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âš ï¸  ğŸŸ  LARANJA: 720 tokens (72.0% do limite)
  âš ï¸     AtenÃ§Ã£o: Aproximando do limite mÃ¡ximo
```

### Limpeza de HistÃ³rico Registrada

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[LIMPEZA DE HISTÃ“RICO]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Removidas 12 mensagens do histÃ³rico
Timestamp: 17/12/2025 14:35:22
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Exemplo de Uso

```python
from chat_openai_memoria import ChatComMemoria

# Ativar debug
chat = ChatComMemoria(
    tamanho_janela=4,
    limite_maximo=400,
    modo_debug=True
)

print(f"Log sendo gravado em: {chat.arquivo_log}\n")

# Conversar normalmente
chat.enviar_mensagem("Explique Python")
chat.enviar_mensagem("E suas vantagens?")
chat.limpar_historico()
chat.enviar_mensagem("Agora explique JavaScript")

# Ao final, verificar o arquivo de log
print(f"\nâœ… SessÃ£o finalizada!")
print(f"ğŸ“„ Log completo salvo em: {chat.arquivo_log}")
```

### AnÃ¡lise dos Logs

Os logs sÃ£o Ãºteis para:

```
âœ… Debugging:
   - Identificar por que o modelo respondeu de certa forma
   - Ver exatamente qual contexto foi enviado
   - Rastrear quando sliding window atuou

âœ… Auditoria:
   - Registro completo de conversas
   - Timestamps precisos
   - ParÃ¢metros utilizados

âœ… OtimizaÃ§Ã£o:
   - Analisar crescimento de tokens
   - Identificar quando alertas aparecem
   - Ajustar janela e limites

âœ… Aprendizado:
   - Entender como memÃ³ria funciona
   - Ver impacto de diferentes configuraÃ§Ãµes
   - Estudar padrÃµes de uso
```

### Desempenho

- **Overhead:** MÃ­nimo (~5-10ms por interaÃ§Ã£o)
- **Tamanho:** ~2-5KB por interaÃ§Ã£o registrada
- **Arquivo:** Novo arquivo por sessÃ£o (nÃ£o acumula)

### Desativando

```python
# OpÃ§Ã£o 1: NÃ£o configurar
chat = ChatComMemoria()  # Debug desativado por padrÃ£o

# OpÃ§Ã£o 2: Explicitamente desativar
chat = ChatComMemoria(modo_debug=False)

# OpÃ§Ã£o 3: No .env
MODO_DEBUG=false
```

---

## ComparaÃ§Ã£o de EstratÃ©gias

### Tabela Resumida

| EstratÃ©gia | AutomaÃ§Ã£o | Economia | Complexidade | Perda de Contexto |
|------------|-----------|----------|--------------|-------------------|
| **Limpeza Manual** | âŒ Nenhuma | â­â­â­ Alta | â­ Baixa | âš ï¸ Total (quando limpa) |
| **Sliding Window** | âœ… Total | â­â­â­ Alta | â­ Baixa | âš ï¸ Gradual |
| **Monitoramento** | âš ï¸ Alertas | â­ Baixa | â­ Baixa | âš ï¸ Nenhuma (sÃ³ alerta) |
| **Sistema Completo** | âœ… Total | â­â­â­ Alta | â­â­ MÃ©dia | âš ï¸ Gradual + Visibilidade |

### Quando Usar Cada Uma

```
Limpeza Manual:
+------------------+
| CenÃ¡rio:         |
| - MÃºltiplos      |
|   clientes       |
| - MudanÃ§a total  |
|   de assunto     |
+------------------+

Sliding Window:
+------------------+
| CenÃ¡rio:         |
| - Conversas      |
|   longas         |
| - FAQ contÃ­nuo   |
| - Tutoriais      |
+------------------+

Monitoramento:
+------------------+
| CenÃ¡rio:         |
| - Visibilidade   |
|   de custos      |
| - Alertas para   |
|   usuÃ¡rio        |
+------------------+

Sistema Completo (RECOMENDADO):
+------------------+
| CenÃ¡rio:         |
| - Uso geral      |
| - ProduÃ§Ã£o       |
| - Controle total |
+------------------+
```

---

## Ferramentas de DiagnÃ³stico

### Comando `/debug`

Exibe status detalhado da memÃ³ria no chat interativo:

```bash
VocÃª: /debug

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      DEBUG DE MEMÃ“RIA                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Status Geral:
   â€¢ Total de mensagens: 12
   â€¢ Pares (user+assistant): 6
   â€¢ Tokens aproximados: 480

ğŸªŸ Sliding Window:
   â€¢ Limite: 8 pares (16 mensagens)
   â€¢ Uso atual: 6 pares (12 mensagens)
   â€¢ Percentual: 75.0%

ğŸ“ˆ Monitoramento:
   â€¢ Limite mÃ¡ximo: 1000 tokens
   â€¢ Uso atual: 480 tokens (48.0%)
   â€¢ NÃ­vel: ğŸŸ¡
   â€¢ Progresso: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]

ğŸ› Modo Debug: Ativo
   â€¢ Arquivo de log: logs/chat_debug_20251217_143045.log
   â€¢ InteraÃ§Ãµes registradas: 6

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Comando `/grafico`

Mostra evoluÃ§Ã£o visual dos tokens:

```bash
VocÃª: /grafico

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      GRÃFICO DE TOKENS                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EvoluÃ§Ã£o de tokens ao longo de 12 mensagens

Max: 480 tokens
 480 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 240 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆâ–ˆ
     |â–ˆâ–ˆ
   0 |â–ˆ
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Mensagens: 1            12

ğŸŸ¡ Uso mÃ¡ximo: 480/1000 tokens (48.0%)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### MÃ©todo `debug_memoria()`

Uso programÃ¡tico:

```python
from chat_openai_memoria import ChatComMemoria

chat = ChatComMemoria(tamanho_janela=6, limite_maximo=800)

# Conversar
chat.enviar_mensagem("Primeira pergunta")
chat.enviar_mensagem("Segunda pergunta")

# Verificar status
chat.debug_memoria()

# Mais conversa
chat.enviar_mensagem("Terceira pergunta")

# Verificar novamente
chat.debug_memoria()
```

### MÃ©todo `grafico_tokens()`

Gera grÃ¡fico ASCII:

```python
chat = ChatComMemoria(tamanho_janela=8, limite_maximo=1000)

# Simular conversa
for i in range(15):
    chat.enviar_mensagem(f"Pergunta nÃºmero {i+1}")

# Mostrar evoluÃ§Ã£o
chat.grafico_tokens()
```

---

## Resumo das Melhores PrÃ¡ticas

### âœ… FaÃ§a

1. **Use o sistema completo** - Combine sliding window + monitoramento
2. **Configure via `.env`** - Facilita ajustes sem mudar cÃ³digo
3. **Monitore tokens** - Use `/debug` ou `debug_memoria()` periodicamente
4. **Ajuste conforme necessÃ¡rio** - Cada caso de uso Ã© diferente
5. **Use modo debug** - Durante desenvolvimento e troubleshooting
6. **Documente escolhas** - Explique por que escolheu valores especÃ­ficos

### âŒ NÃ£o FaÃ§a

1. **NÃ£o ignore alertas** - Custos podem crescer inesperadamente
2. **NÃ£o use janela muito pequena** - Perde contexto Ãºtil
3. **NÃ£o desabilite tudo** - Sem gerenciamento, custos explodem
4. **NÃ£o use valores fixos** - Adapte ao caso de uso
5. **NÃ£o esqueÃ§a de testar** - Valide configuraÃ§Ãµes com dados reais

### ConfiguraÃ§Ã£o Inicial Recomendada

```env
# .env - ConfiguraÃ§Ã£o segura para comeÃ§ar
OPENAI_API_KEY=sua-chave-aqui
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000

# Gerenciamento de memÃ³ria (valores conservadores)
JANELA_MAX=6
LIMITE_MAXIMO=800
MODO_DEBUG=false  # true durante desenvolvimento
```

---

## PrÃ³ximos Passos

- ğŸ’¡ Veja aplicaÃ§Ãµes prÃ¡ticas em [CASOS_DE_USO.md](CASOS_DE_USO.md)
- ğŸ”§ Resolva problemas em [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
- ğŸ“š Revise conceitos em [CONCEITOS.md](CONCEITOS.md)
- ğŸ“ Experimente os exemplos: `python exemplos_avancados.py`
